#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘é¢„å¤„ç†æ¨¡å—
æå–è§†é¢‘å¸§ï¼Œè½¬æ¢ä¸ºå¼ é‡æ ¼å¼ï¼Œç”¨äºåç»­è®­ç»ƒ
"""

import os
import cv2
import torch
import numpy as np
from pathlib import Path
from typing import List, Tuple, Optional
import argparse
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor, as_completed
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VideoProcessor:
    """è§†é¢‘é¢„å¤„ç†å™¨"""
    
    def __init__(
        self,
        num_frames: int = 16,
        resolution: int = 224,
        sampling_strategy: str = "uniform",
        normalize: bool = True
    ):
        """
        å‚æ•°:
            num_frames: æ¯ä¸ªè§†é¢‘é‡‡æ ·çš„å¸§æ•°
            resolution: è¾“å‡ºåˆ†è¾¨ç‡ (resolution x resolution)
            sampling_strategy: é‡‡æ ·ç­–ç•¥ ('uniform', 'random', 'dense')
            normalize: æ˜¯å¦å½’ä¸€åŒ–åˆ°[0,1]
        """
        self.num_frames = num_frames
        self.resolution = resolution
        self.sampling_strategy = sampling_strategy
        self.normalize = normalize
        
        # ImageNetæ ‡å‡†åŒ–å‚æ•°
        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1, 1)
        self.std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1, 1)
    
    def read_video(self, video_path: str) -> Optional[np.ndarray]:
        """
        è¯»å–è§†é¢‘æ–‡ä»¶
        
        è¿”å›:
            frames: (T, H, W, C) numpyæ•°ç»„ï¼ŒBGRæ ¼å¼
        """
        video_path = Path(video_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not video_path.exists():
            logger.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None
        
        if not video_path.is_file():
            logger.error(f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {video_path}")
            return None
        
        try:
            # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿OpenCVèƒ½æ­£ç¡®è¯»å–
            cap = cv2.VideoCapture(str(video_path.resolve()))
            
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
                # å°è¯•è·å–æ›´å¤šé”™è¯¯ä¿¡æ¯
                logger.error(f"æ–‡ä»¶å¤§å°: {video_path.stat().st_size if video_path.exists() else 'N/A'} bytes")
                return None
            
            # è·å–è§†é¢‘å±æ€§ç”¨äºéªŒè¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            logger.debug(f"è§†é¢‘ä¿¡æ¯: {video_path.name} - {frame_count}å¸§, {fps:.2f}fps, {width}x{height}")
            
            frames = []
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                frames.append(frame)
            
            cap.release()
            
            if len(frames) == 0:
                logger.error(f"è§†é¢‘ä¸ºç©ºæˆ–æ— æ³•è¯»å–å¸§: {video_path}")
                return None
            
            return np.stack(frames, axis=0)  # (T, H, W, C)
        
        except Exception as e:
            logger.error(f"è¯»å–è§†é¢‘å¤±è´¥ {video_path}: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None
    
    def sample_frames(self, frames: np.ndarray) -> np.ndarray:
        """
        é‡‡æ ·å›ºå®šæ•°é‡çš„å¸§
        
        å‚æ•°:
            frames: (T, H, W, C) åŸå§‹å¸§
        
        è¿”å›:
            sampled_frames: (num_frames, H, W, C)
        """
        total_frames = len(frames)
        
        if total_frames < self.num_frames:
            # å¸§æ•°ä¸è¶³ï¼Œé‡å¤æœ€åä¸€å¸§
            logger.warning(f"è§†é¢‘å¸§æ•°ä¸è¶³ ({total_frames} < {self.num_frames})ï¼Œå¡«å……æœ€åä¸€å¸§")
            padding = [frames[-1]] * (self.num_frames - total_frames)
            frames = np.concatenate([frames, np.stack(padding, axis=0)], axis=0)
            total_frames = len(frames)
        
        if self.sampling_strategy == "uniform":
            # å‡åŒ€é‡‡æ ·
            indices = np.linspace(0, total_frames - 1, self.num_frames, dtype=int)
        
        elif self.sampling_strategy == "random":
            # éšæœºé‡‡æ ·
            indices = np.sort(np.random.choice(total_frames, self.num_frames, replace=False))
        
        elif self.sampling_strategy == "dense":
            # ä»å¼€å¤´å¯†é›†é‡‡æ ·
            indices = np.arange(min(self.num_frames, total_frames))
            if len(indices) < self.num_frames:
                indices = np.pad(indices, (0, self.num_frames - len(indices)), 
                                constant_values=indices[-1])
        else:
            raise ValueError(f"æœªçŸ¥çš„é‡‡æ ·ç­–ç•¥: {self.sampling_strategy}")
        
        return frames[indices]
    
    def resize_frames(self, frames: np.ndarray) -> np.ndarray:
        """
        è°ƒæ•´å¸§å¤§å°
        
        å‚æ•°:
            frames: (T, H, W, C)
        
        è¿”å›:
            resized_frames: (T, resolution, resolution, C)
        """
        resized = []
        for frame in frames:
            # OpenCV resize (H, W)
            frame_resized = cv2.resize(
                frame, 
                (self.resolution, self.resolution),
                interpolation=cv2.INTER_LINEAR
            )
            resized.append(frame_resized)
        
        return np.stack(resized, axis=0)
    
    def to_tensor(self, frames: np.ndarray) -> torch.Tensor:
        """
        è½¬æ¢ä¸ºPyTorchå¼ é‡
        
        å‚æ•°:
            frames: (T, H, W, C) BGRæ ¼å¼, uint8, [0, 255]
        
        è¿”å›:
            tensor: (C, T, H, W) RGBæ ¼å¼, float32, [0, 1] æˆ– å½’ä¸€åŒ–å
        """
        # BGRè½¬RGB
        frames = frames[..., ::-1].copy()  # (T, H, W, C)
        
        # è½¬æ¢ä¸ºfloatå¹¶å½’ä¸€åŒ–åˆ°[0, 1]
        frames = frames.astype(np.float32) / 255.0
        
        # è½¬æ¢ä¸ºtensorå¹¶è°ƒæ•´ç»´åº¦: (T, H, W, C) -> (C, T, H, W)
        tensor = torch.from_numpy(frames).permute(3, 0, 1, 2)
        
        # ImageNetæ ‡å‡†åŒ–
        if self.normalize:
            tensor = (tensor - self.mean) / self.std
        
        return tensor
    
    def process_single_video(
        self, 
        video_path: str, 
        output_path: Optional[str] = None
    ) -> Optional[torch.Tensor]:
        """
        å¤„ç†å•ä¸ªè§†é¢‘
        
        å‚æ•°:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡º.ptæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
        è¿”å›:
            tensor: (C, T, H, W) æˆ– Noneï¼ˆå¤±è´¥æ—¶ï¼‰
        """
        # è¯»å–è§†é¢‘
        frames = self.read_video(video_path)
        if frames is None:
            return None
        
        # é‡‡æ ·å¸§
        frames = self.sample_frames(frames)
        
        # è°ƒæ•´å¤§å°
        frames = self.resize_frames(frames)
        
        # è½¬æ¢ä¸ºtensor
        tensor = self.to_tensor(frames)
        
        # ä¿å­˜ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼‰
        if output_path is not None:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            torch.save(tensor, output_path)
            logger.debug(f"å·²ä¿å­˜: {output_path}")
        
        return tensor
    
    def process_video_batch(
        self,
        video_dir: str,
        output_dir: str,
        num_workers: int = 4,
        file_extension: str = "*.mp4",
        recursive: bool = True
    ):
        """
        æ‰¹é‡å¤„ç†è§†é¢‘ç›®å½•
        
        å‚æ•°:
            video_dir: è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
            num_workers: å¹¶è¡Œè¿›ç¨‹æ•°
            file_extension: è§†é¢‘æ–‡ä»¶æ‰©å±•åæ¨¡å¼
            recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•ï¼ˆé»˜è®¤: Trueï¼‰
        """
        video_dir = Path(video_dir)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒé€’å½’æœç´¢ï¼‰
        if recursive:
            # é€’å½’æœç´¢æ‰€æœ‰å­ç›®å½•ä¸­çš„è§†é¢‘æ–‡ä»¶
            pattern = f"**/{file_extension}" if not file_extension.startswith("**/") else file_extension
            video_files = list(video_dir.glob(pattern))
        else:
            # åªæœç´¢å½“å‰ç›®å½•
            video_files = list(video_dir.glob(file_extension))
        
        if len(video_files) == 0:
            logger.error(f"åœ¨ {video_dir} ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ ({file_extension}, recursive={recursive})")
            return
        
        logger.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        logger.info(f"é…ç½®: {self.num_frames}å¸§, {self.resolution}x{self.resolution}, {self.sampling_strategy}é‡‡æ ·")
        
        # æ„å»ºè¾“å…¥è¾“å‡ºè·¯å¾„å¯¹
        tasks = []
        for video_path in video_files:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä¿æŒç›®å½•ç»“æ„æˆ–ä½¿ç”¨å”¯ä¸€æ–‡ä»¶å
            try:
                relative_path = video_path.relative_to(video_dir)
                # å°†è·¯å¾„ä¸­çš„ç›®å½•åˆ†éš”ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œåˆ›å»ºå”¯ä¸€æ–‡ä»¶å
                # ä¾‹å¦‚: S1_C3_E144_V0060_ID1_T1/S1_C3_E144_V0060_ID1_T1_c0.mp4 
                # -> S1_C3_E144_V0060_ID1_T1_S1_C3_E144_V0060_ID1_T1_c0.pt
                safe_name = str(relative_path).replace(os.sep, "_").replace("/", "_").replace("\\", "_")
                safe_name = safe_name.replace(".mp4", ".pt").replace(".avi", ".pt").replace(".mov", ".pt")
                output_path = output_dir / safe_name
            except ValueError:
                # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨æ–‡ä»¶å
                output_path = output_dir / f"{video_path.stem}.pt"
            
            # è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
            if output_path.exists():
                logger.debug(f"å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_path}")
                continue
            
            tasks.append((str(video_path), str(output_path)))
        
        if len(tasks) == 0:
            logger.info("æ‰€æœ‰è§†é¢‘å·²å¤„ç†å®Œæˆï¼")
            return
        
        logger.info(f"éœ€è¦å¤„ç† {len(tasks)} ä¸ªè§†é¢‘")
        
        # å¤šè¿›ç¨‹å¤„ç†
        success_count = 0
        failed_count = 0
        
        if num_workers > 1:
            with ProcessPoolExecutor(max_workers=num_workers) as executor:
                futures = {
                    executor.submit(self._process_wrapper, video_path, output_path): (video_path, output_path)
                    for video_path, output_path in tasks
                }
                
                with tqdm(total=len(tasks), desc="å¤„ç†è§†é¢‘") as pbar:
                    for future in as_completed(futures):
                        video_path, output_path = futures[future]
                        try:
                            result = future.result()
                            if result:
                                success_count += 1
                            else:
                                failed_count += 1
                                logger.error(f"å¤„ç†å¤±è´¥: {video_path}")
                        except Exception as e:
                            failed_count += 1
                            logger.error(f"å¤„ç†å¼‚å¸¸ {video_path}: {e}")
                        pbar.update(1)
        else:
            # å•è¿›ç¨‹
            for video_path, output_path in tqdm(tasks, desc="å¤„ç†è§†é¢‘"):
                result = self.process_single_video(video_path, output_path)
                if result is not None:
                    success_count += 1
                else:
                    failed_count += 1
        
        # è¾“å‡ºç»Ÿè®¡
        logger.info("=" * 70)
        logger.info("å¤„ç†å®Œæˆï¼")
        logger.info(f"âœ… æˆåŠŸ: {success_count}")
        logger.info(f"âŒ å¤±è´¥: {failed_count}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info("=" * 70)
    
    def _process_wrapper(self, video_path: str, output_path: str) -> bool:
        """å¤šè¿›ç¨‹åŒ…è£…å‡½æ•°"""
        try:
            result = self.process_single_video(video_path, output_path)
            return result is not None
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥ {video_path}: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(description="è§†é¢‘é¢„å¤„ç†å·¥å…·")
    parser.add_argument(
        "--video_dir",
        type=str,
        required=True,
        help="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        required=True,
        help="è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„"
    )
    parser.add_argument(
        "--num_frames",
        type=int,
        default=16,
        help="æ¯ä¸ªè§†é¢‘é‡‡æ ·å¸§æ•° (é»˜è®¤: 16)"
    )
    parser.add_argument(
        "--resolution",
        type=int,
        default=224,
        help="è¾“å‡ºåˆ†è¾¨ç‡ (é»˜è®¤: 224)"
    )
    parser.add_argument(
        "--sampling_strategy",
        type=str,
        default="uniform",
        choices=["uniform", "random", "dense"],
        help="å¸§é‡‡æ ·ç­–ç•¥ (é»˜è®¤: uniform)"
    )
    parser.add_argument(
        "--num_workers",
        type=int,
        default=4,
        help="å¹¶è¡Œè¿›ç¨‹æ•° (é»˜è®¤: 4)"
    )
    parser.add_argument(
        "--file_extension",
        type=str,
        default="*.mp4",
        help="è§†é¢‘æ–‡ä»¶æ‰©å±•å (é»˜è®¤: *.mp4)"
    )
    parser.add_argument(
        "--no_recursive",
        action="store_true",
        help="ä¸é€’å½’æœç´¢å­ç›®å½•ï¼ˆé»˜è®¤ä¼šé€’å½’æœç´¢ï¼‰"
    )
    parser.add_argument(
        "--no_normalize",
        action="store_true",
        help="ä¸è¿›è¡ŒImageNetæ ‡å‡†åŒ–"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = VideoProcessor(
        num_frames=args.num_frames,
        resolution=args.resolution,
        sampling_strategy=args.sampling_strategy,
        normalize=not args.no_normalize
    )
    
    # æ‰¹é‡å¤„ç†
    processor.process_video_batch(
        video_dir=args.video_dir,
        output_dir=args.output_dir,
        num_workers=args.num_workers,
        file_extension=args.file_extension,
        recursive=not args.no_recursive
    )


if __name__ == "__main__":
    main()