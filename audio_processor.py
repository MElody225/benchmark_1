#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘é¢„å¤„ç†æ¨¡å—
å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºMelé¢‘è°±å›¾ï¼Œç”¨äºåç»­è®­ç»ƒ
"""

import os
import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
from typing import Optional, Tuple
import argparse
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor, as_completed
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AudioProcessor:
    """éŸ³é¢‘é¢„å¤„ç†å™¨"""
    
    def __init__(
        self,
        sample_rate: int = 16000,
        duration: float = 10.0,
        n_mels: int = 128,
        n_fft: int = 2048,
        hop_length: int = 512,
        win_length: Optional[int] = None,
        window: str = "hann",
        fmin: float = 0,
        fmax: Optional[float] = None,
        normalize: bool = True
    ):
        """
        å‚æ•°:
            sample_rate: ç›®æ ‡é‡‡æ ·ç‡ (Hz)
            duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œä¸è¶³åˆ™å¡«å……ï¼Œè¶…è¿‡åˆ™æˆªæ–­
            n_mels: Melé¢‘è°±é€šé“æ•°
            n_fft: FFTçª—å£å¤§å°
            hop_length: å¸§ç§»
            win_length: çª—å£é•¿åº¦
            window: çª—å‡½æ•°ç±»å‹
            fmin: æœ€å°é¢‘ç‡
            fmax: æœ€å¤§é¢‘ç‡ï¼ˆNoneåˆ™ä¸ºsample_rate/2ï¼‰
            normalize: æ˜¯å¦å½’ä¸€åŒ–
        """
        self.sample_rate = sample_rate
        self.duration = duration
        self.n_mels = n_mels
        self.n_fft = n_fft
        self.hop_length = hop_length
        self.win_length = win_length if win_length else n_fft
        self.window = window
        self.fmin = fmin
        self.fmax = fmax if fmax else sample_rate / 2.0
        self.normalize = normalize
        
        # è®¡ç®—æœŸæœ›çš„æ ·æœ¬æ•°
        self.expected_samples = int(sample_rate * duration)
    
    def load_audio(self, audio_path: str) -> Optional[np.ndarray]:
        """
        åŠ è½½éŸ³é¢‘æ–‡ä»¶
        
        è¿”å›:
            audio: (n_samples,) å•å£°é“éŸ³é¢‘ï¼Œé‡‡æ ·ç‡ä¸ºself.sample_rate
        """
        audio_path = Path(audio_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not audio_path.exists():
            logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return None
        
        if not audio_path.is_file():
            logger.error(f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {audio_path}")
            return None
        
        try:
            # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿librosaèƒ½æ­£ç¡®è¯»å–
            # åŠ è½½éŸ³é¢‘å¹¶é‡é‡‡æ ·
            audio, sr = librosa.load(str(audio_path.resolve()), sr=self.sample_rate, mono=True)
            
            if audio is None or len(audio) == 0:
                logger.error(f"éŸ³é¢‘ä¸ºç©º: {audio_path}")
                return None
            
            # è®°å½•éŸ³é¢‘ä¿¡æ¯
            duration = len(audio) / self.sample_rate
            logger.debug(f"éŸ³é¢‘ä¿¡æ¯: {audio_path.name} - {duration:.2f}s, {len(audio)} samples")
            
            return audio
        
        except Exception as e:
            logger.error(f"åŠ è½½éŸ³é¢‘å¤±è´¥ {audio_path}: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None
    
    def pad_or_truncate(self, audio: np.ndarray) -> np.ndarray:
        """
        å¡«å……æˆ–æˆªæ–­éŸ³é¢‘åˆ°å›ºå®šé•¿åº¦
        
        å‚æ•°:
            audio: (n_samples,)
        
        è¿”å›:
            audio: (expected_samples,)
        """
        if len(audio) > self.expected_samples:
            # æˆªæ–­ï¼ˆä»ä¸­é—´æˆªå–ï¼Œä¿ç•™æœ€é‡è¦çš„éƒ¨åˆ†ï¼‰
            start = (len(audio) - self.expected_samples) // 2
            audio = audio[start:start + self.expected_samples]
            logger.debug(f"éŸ³é¢‘æˆªæ–­: {len(audio) + start} -> {len(audio)} samples")
        
        elif len(audio) < self.expected_samples:
            # å¡«å……ï¼ˆé›¶å¡«å……åˆ°æœ«å°¾ï¼‰
            padding = self.expected_samples - len(audio)
            audio = np.pad(audio, (0, padding), mode='constant')
            logger.debug(f"éŸ³é¢‘å¡«å……: {len(audio) - padding} -> {len(audio)} samples")
        
        return audio
    
    def compute_mel_spectrogram(self, audio: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—Melé¢‘è°±å›¾
        
        å‚æ•°:
            audio: (n_samples,) éŸ³é¢‘ä¿¡å·
        
        è¿”å›:
            mel_spec: (n_mels, n_frames) Melé¢‘è°±å›¾
        """
        # è®¡ç®—çŸ­æ—¶å‚…é‡Œå¶å˜æ¢
        stft = librosa.stft(
            audio,
            n_fft=self.n_fft,
            hop_length=self.hop_length,
            win_length=self.win_length,
            window=self.window
        )
        
        # è®¡ç®—å¹…åº¦è°±
        magnitude = np.abs(stft)
        
        # è½¬æ¢ä¸ºMelé¢‘è°±
        mel_spec = librosa.feature.melspectrogram(
            S=magnitude ** 2,  # åŠŸç‡è°±
            sr=self.sample_rate,
            n_mels=self.n_mels,
            fmin=self.fmin,
            fmax=self.fmax
        )
        
        # è½¬æ¢ä¸ºdBå°ºåº¦ï¼ˆlog-Melï¼‰
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
        
        return mel_spec_db
    
    def normalize_spectrogram(self, mel_spec: np.ndarray) -> np.ndarray:
        """
        å½’ä¸€åŒ–é¢‘è°±å›¾åˆ°[0, 1]
        
        å‚æ•°:
            mel_spec: (n_mels, n_frames) dBå°ºåº¦
        
        è¿”å›:
            normalized: (n_mels, n_frames) [0, 1]
        """
        # dBèŒƒå›´é€šå¸¸æ˜¯[-80, 0]
        # å½’ä¸€åŒ–åˆ°[0, 1]
        min_val = mel_spec.min()
        max_val = mel_spec.max()
        
        # å¤„ç†å…¨é›¶æˆ–å¸¸æ•°å€¼çš„æƒ…å†µ
        if max_val - min_val < 1e-8:
            # å¦‚æœæ‰€æœ‰å€¼ç›¸åŒï¼Œè¿”å›é›¶çŸ©é˜µæˆ–ä¿æŒåŸå€¼
            if abs(max_val) < 1e-8:
                return np.zeros_like(mel_spec)
            else:
                # å¸¸æ•°å€¼å½’ä¸€åŒ–åˆ°0.5
                return np.ones_like(mel_spec) * 0.5
        
        mel_spec_norm = (mel_spec - min_val) / (max_val - min_val)
        return mel_spec_norm
    
    def resize_spectrogram(self, mel_spec: np.ndarray, target_width: int = 128) -> np.ndarray:
        """
        è°ƒæ•´é¢‘è°±å›¾å®½åº¦ï¼ˆæ—¶é—´ç»´åº¦ï¼‰
        
        å‚æ•°:
            mel_spec: (n_mels, n_frames)
            target_width: ç›®æ ‡å®½åº¦
        
        è¿”å›:
            resized: (n_mels, target_width)
        """
        from scipy.ndimage import zoom
        
        current_width = mel_spec.shape[1]
        
        if current_width == target_width:
            return mel_spec
        
        # è®¡ç®—ç¼©æ”¾å› å­
        zoom_factor = target_width / current_width
        
        # è°ƒæ•´å¤§å°ï¼ˆä»…æ—¶é—´è½´ï¼‰
        resized = zoom(mel_spec, (1.0, zoom_factor), order=1)
        
        return resized
    
    def process_single_audio(
        self,
        audio_path: str,
        output_path: Optional[str] = None,
        target_shape: Tuple[int, int] = (128, 128)
    ) -> Optional[np.ndarray]:
        """
        å¤„ç†å•ä¸ªéŸ³é¢‘æ–‡ä»¶
        
        å‚æ•°:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡º.npyæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            target_shape: ç›®æ ‡é¢‘è°±å›¾å½¢çŠ¶ (height, width)
        
        è¿”å›:
            mel_spec: (n_mels, target_width) æˆ– Noneï¼ˆå¤±è´¥æ—¶ï¼‰
        """
        # åŠ è½½éŸ³é¢‘
        audio = self.load_audio(audio_path)
        if audio is None:
            return None
        
        # å¡«å……æˆ–æˆªæ–­
        audio = self.pad_or_truncate(audio)
        
        # è®¡ç®—Melé¢‘è°±å›¾
        mel_spec = self.compute_mel_spectrogram(audio)
        
        # å½’ä¸€åŒ–
        if self.normalize:
            mel_spec = self.normalize_spectrogram(mel_spec)
        
        # è°ƒæ•´åˆ°ç›®æ ‡å½¢çŠ¶
        if target_shape:
            target_height, target_width = target_shape
            
            # è°ƒæ•´é«˜åº¦ï¼ˆé¢‘ç‡ç»´åº¦ï¼‰
            if mel_spec.shape[0] != target_height:
                from scipy.ndimage import zoom
                zoom_factor = target_height / mel_spec.shape[0]
                mel_spec = zoom(mel_spec, (zoom_factor, 1.0), order=1)
            
            # è°ƒæ•´å®½åº¦ï¼ˆæ—¶é—´ç»´åº¦ï¼‰
            mel_spec = self.resize_spectrogram(mel_spec, target_width)
        
        # ä¿å­˜ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼‰
        if output_path is not None:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            np.save(output_path, mel_spec.astype(np.float32))
            logger.debug(f"å·²ä¿å­˜: {output_path}")
        
        return mel_spec
    
    def process_audio_batch(
        self,
        audio_dir: str,
        output_dir: str,
        num_workers: int = 4,
        file_extension: str = "*.wav",
        target_shape: Tuple[int, int] = (128, 128),
        recursive: bool = True
    ):
        """
        æ‰¹é‡å¤„ç†éŸ³é¢‘ç›®å½•
        
        å‚æ•°:
            audio_dir: éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
            num_workers: å¹¶è¡Œè¿›ç¨‹æ•°
            file_extension: éŸ³é¢‘æ–‡ä»¶æ‰©å±•åæ¨¡å¼
            target_shape: ç›®æ ‡é¢‘è°±å›¾å½¢çŠ¶
            recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•ï¼ˆé»˜è®¤: Trueï¼‰
        """
        audio_dir = Path(audio_dir)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒé€’å½’æœç´¢ï¼‰
        if recursive:
            # é€’å½’æœç´¢æ‰€æœ‰å­ç›®å½•ä¸­çš„éŸ³é¢‘æ–‡ä»¶
            pattern = f"**/{file_extension}" if not file_extension.startswith("**/") else file_extension
            audio_files = list(audio_dir.glob(pattern))
        else:
            # åªæœç´¢å½“å‰ç›®å½•
            audio_files = list(audio_dir.glob(file_extension))
        
        if len(audio_files) == 0:
            logger.error(f"åœ¨ {audio_dir} ä¸­æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ({file_extension}, recursive={recursive})")
            return
        
        logger.info(f"æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        logger.info(f"é…ç½®: {self.sample_rate}Hz, {self.duration}s, {self.n_mels} Melé€šé“")
        logger.info(f"è¾“å‡ºå½¢çŠ¶: {target_shape}")
        
        # æ„å»ºè¾“å…¥è¾“å‡ºè·¯å¾„å¯¹
        tasks = []
        for audio_path in audio_files:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä¿æŒç›®å½•ç»“æ„æˆ–ä½¿ç”¨å”¯ä¸€æ–‡ä»¶å
            try:
                relative_path = audio_path.relative_to(audio_dir)
                # å°†è·¯å¾„ä¸­çš„ç›®å½•åˆ†éš”ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œåˆ›å»ºå”¯ä¸€æ–‡ä»¶å
                # ä¾‹å¦‚: S1_C3_E144_V0060_ID1_T1/S1_C3_E144_V0060_ID1_T1_c0.wav 
                # -> S1_C3_E144_V0060_ID1_T1_S1_C3_E144_V0060_ID1_T1_c0.npy
                safe_name = str(relative_path).replace(os.sep, "_").replace("/", "_").replace("\\", "_")
                safe_name = safe_name.replace(".wav", ".npy").replace(".mp3", ".npy").replace(".flac", ".npy")
                output_path = output_dir / safe_name
            except ValueError:
                # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨æ–‡ä»¶å
                output_path = output_dir / f"{audio_path.stem}.npy"
            
            # è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
            if output_path.exists():
                logger.debug(f"å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_path}")
                continue
            
            tasks.append((str(audio_path), str(output_path)))
        
        if len(tasks) == 0:
            logger.info("æ‰€æœ‰éŸ³é¢‘å·²å¤„ç†å®Œæˆï¼")
            return
        
        logger.info(f"éœ€è¦å¤„ç† {len(tasks)} ä¸ªéŸ³é¢‘")
        
        # å¤šè¿›ç¨‹å¤„ç†
        success_count = 0
        failed_count = 0
        
        if num_workers > 1:
            with ProcessPoolExecutor(max_workers=num_workers) as executor:
                futures = {
                    executor.submit(self._process_wrapper, audio_path, output_path, target_shape): (audio_path, output_path)
                    for audio_path, output_path in tasks
                }
                
                with tqdm(total=len(tasks), desc="å¤„ç†éŸ³é¢‘") as pbar:
                    for future in as_completed(futures):
                        audio_path, output_path = futures[future]
                        try:
                            result = future.result()
                            if result:
                                success_count += 1
                            else:
                                failed_count += 1
                                logger.error(f"å¤„ç†å¤±è´¥: {audio_path}")
                        except Exception as e:
                            failed_count += 1
                            logger.error(f"å¤„ç†å¼‚å¸¸ {audio_path}: {e}")
                        pbar.update(1)
        else:
            # å•è¿›ç¨‹
            for audio_path, output_path in tqdm(tasks, desc="å¤„ç†éŸ³é¢‘"):
                result = self.process_single_audio(audio_path, output_path, target_shape)
                if result is not None:
                    success_count += 1
                else:
                    failed_count += 1
        
        # è¾“å‡ºç»Ÿè®¡
        logger.info("=" * 70)
        logger.info("å¤„ç†å®Œæˆï¼")
        logger.info(f"âœ… æˆåŠŸ: {success_count}")
        logger.info(f"âŒ å¤±è´¥: {failed_count}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info("=" * 70)
    
    def _process_wrapper(self, audio_path: str, output_path: str, target_shape: Tuple[int, int]) -> bool:
        """å¤šè¿›ç¨‹åŒ…è£…å‡½æ•°"""
        try:
            result = self.process_single_audio(audio_path, output_path, target_shape)
            return result is not None
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥ {audio_path}: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(description="éŸ³é¢‘é¢„å¤„ç†å·¥å…·")
    parser.add_argument(
        "--audio_dir",
        type=str,
        required=True,
        help="éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        required=True,
        help="è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„"
    )
    parser.add_argument(
        "--sample_rate",
        type=int,
        default=16000,
        help="ç›®æ ‡é‡‡æ ·ç‡ (é»˜è®¤: 16000)"
    )
    parser.add_argument(
        "--duration",
        type=float,
        default=10.0,
        help="éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ (é»˜è®¤: 10.0)"
    )
    parser.add_argument(
        "--n_mels",
        type=int,
        default=128,
        help="Melé¢‘è°±é€šé“æ•° (é»˜è®¤: 128)"
    )
    parser.add_argument(
        "--target_width",
        type=int,
        default=128,
        help="ç›®æ ‡é¢‘è°±å›¾å®½åº¦ (é»˜è®¤: 128)"
    )
    parser.add_argument(
        "--num_workers",
        type=int,
        default=4,
        help="å¹¶è¡Œè¿›ç¨‹æ•° (é»˜è®¤: 4)"
    )
    parser.add_argument(
        "--file_extension",
        type=str,
        default="*.wav",
        help="éŸ³é¢‘æ–‡ä»¶æ‰©å±•å (é»˜è®¤: *.wav)"
    )
    parser.add_argument(
        "--no_recursive",
        action="store_true",
        help="ä¸é€’å½’æœç´¢å­ç›®å½•ï¼ˆé»˜è®¤ä¼šé€’å½’æœç´¢ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = AudioProcessor(
        sample_rate=args.sample_rate,
        duration=args.duration,
        n_mels=args.n_mels
    )
    
    # æ‰¹é‡å¤„ç†
    processor.process_audio_batch(
        audio_dir=args.audio_dir,
        output_dir=args.output_dir,
        num_workers=args.num_workers,
        file_extension=args.file_extension,
        target_shape=(args.n_mels, args.target_width),
        recursive=not args.no_recursive
    )


if __name__ == "__main__":
    main()